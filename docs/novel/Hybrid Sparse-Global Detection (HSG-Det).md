## ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà (Blend Novel Structure)

**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:**

* ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 1080p memory ‡∏î‡∏µ
* Dense objects ‡∏î‡∏µ‡∏°‡∏≤‡∏Å
* Occlusion ‡∏î‡∏µ‡∏°‡∏≤‡∏Å
* Latency ‡∏ï‡πà‡∏≥
* Post-process optional
* Stability ‡∏™‡∏π‡∏á

---

# ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î: **Hybrid Sparse-Global Detection (HSG-Det)**

> ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á CNN-grid (‡πÄ‡∏£‡πá‡∏ß, memory ‡∏î‡∏µ)
>
> * Sparse Query Attention (global reasoning)
> * One-to-many ‚Üí One-to-one adaptive matching

---

# 1Ô∏è‚É£ Backbone ‚Äî Efficient Dense Encoder

### ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á

* CSP/C2f-style residual split (‡∏•‡∏î redundancy)
* Stride pyramid: 8 / 16 / 32
* Depthwise separable conv ‡∏ö‡∏≤‡∏á stage
* Partial global context block (low-res only)

### ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£

* 1080p ‚Üí ‡πÉ‡∏ä‡πâ stride 8 ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
  ‚Üí feature ~ 240√ó135
* Global attention ‡∏ó‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞ stride 32 (‚âà 30√ó17)

[
\text{Memory} \sim O((HW)_{low}^2)
]

‚Üí memory ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÑ‡∏î‡πâ

### ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥

* Dense objects ‡∏î‡∏µ‡∏°‡∏≤‡∏Å (grid retains locality)
* Memory efficient
* Gradient stable (CSP split)

---

# 2Ô∏è‚É£ Neck ‚Äî Dual-Path Fusion

### Path A: Local Path (PAN/FPN style)

‡∏£‡∏±‡∏Å‡∏©‡∏≤ spatial detail

### Path B: Sparse Global Tokens

* Extract K salient tokens per scale (top-k activation)
* Cross-scale aggregation

[
K \ll HW
]

‚Üí complexity ‡∏ï‡πà‡∏≥

### ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

* Scale ambiguity ‡∏•‡∏î
* Occlusion reasoning ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
* Latency ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥ (sparse attention)

---

# 3Ô∏è‚É£ Head ‚Äî Dual-Mode Decoupled Head

### Branch 1: Dense Grid Head

* Anchor-free
* Predict box + cls per cell
* Fast, dense coverage

### Branch 2: Sparse Query Head

* N = 200 learnable queries
* Cross-attention ‡∏Å‡∏±‡∏ö global tokens
* Predict refined boxes

### Output merge:

* During training ‚Üí both active
* During inference:

  * Fast mode ‚Üí grid only
  * High-accuracy mode ‚Üí fuse both

---

# 4Ô∏è‚É£ Detection / Assignment ‚Äî Adaptive Matching

### Early training:

Dynamic many-to-one (SimOTA-like)

### Late training:

Gradually shift to one-to-one (Hungarian-lite)

[
\alpha(t) \rightarrow 1
]

‚Üí Transition matching scheme

### Result:

* Stable early training
* NMS optional
* Duplicate ‡∏•‡∏î‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏° learned uniqueness

---

# üî¨ ‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥

| Requirement           | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà HSG-Det ‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå                       |
| --------------------- | ---------------------------------------------- |
| 1080p memory ‡∏î‡∏µ       | Global attention ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ low-res + sparse tokens |
| Dense objects ‡∏î‡∏µ‡∏°‡∏≤‡∏Å   | Grid branch ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å cell                   |
| Occlusion ‡∏î‡∏µ‡∏°‡∏≤‡∏Å       | Query branch reasoning global                  |
| Latency ‡∏ï‡πà‡∏≥           | Grid inference mode                            |
| Post-process optional | One-to-one refinement                          |
| Stability ‡∏™‡∏π‡∏á         | CSP backbone + progressive assignment          |

---

# üîÅ Complexity Overview

Let:

* Grid cells ‚âà 32k (stride 8)
* Sparse tokens K ‚âà 256
* Queries N ‚âà 200

Total cost:

[
O(HW) + O(KN)
]

‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô:

[
O((HW)^2)
]

---

# üéØ ‡∏ó‡∏≥‡πÑ‡∏°‡∏°‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ YOLO ‡πÅ‡∏•‡∏∞ DETR ‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á ‡πÜ

| Model   | ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î                                         |
| ------- | ------------------------------------------------ |
| YOLO    | ‡πÑ‡∏°‡πà‡∏°‡∏µ global reasoning                           |
| DETR    | Latency ‡∏™‡∏π‡∏á, convergence ‡∏ä‡πâ‡∏≤                     |
| HSG-Det | Retain locality + inject sparse global reasoning |

---

# üß† ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á Entropy

Grid branch:
[
H_{local} \downarrow
]

Query branch:
[
H_{global} \downarrow
]

‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô:
[
H(Y|X;\theta) \text{ ‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó}
]

---

# üì¶ Deployment Modes

| Mode     | ‡πÉ‡∏ä‡πâ branch                 | ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö      |
| -------- | -------------------------- | ------------- |
| Edge     | Grid only                  | Real-time     |
| Balanced | Grid + few queries         | Smart cameras |
| Full     | Grid + full sparse queries | Research      |

---

# üîÆ ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°

‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà:

* ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢ speed ‡πÅ‡∏ö‡∏ö DETR
* ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢ global context ‡πÅ‡∏ö‡∏ö YOLO
* ‡πÑ‡∏°‡πà explode memory ‡∏ó‡∏µ‡πà 1080p
* ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á NMS ‡πÄ‡∏™‡∏°‡∏≠‡πÑ‡∏õ
* Stable training ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà pure transformer

---

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠:

* ‡∏ß‡∏≤‡∏î architecture block diagram
* ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì FLOPs ‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà 1080p
* ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô pseudo-YAML ‡πÅ‡∏ö‡∏ö ultralytics
* ‡∏´‡∏£‡∏∑‡∏≠ formalize ‡πÄ‡∏õ‡πá‡∏ô theorem ‡πÄ‡∏ä‡∏¥‡∏á entropy bound

‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ.
